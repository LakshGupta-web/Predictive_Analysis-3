# Learning Probability Density Functions using GANs

## Project Overview
This project demonstrates the ability of a Generative Adversarial Network (GAN) to learn an unknown probability density function (PDF) of a transformed random variable. The base feature used is the NO2 concentration from the India Air Quality dataset.

---

## 1. Transformation Parameters
Based on the university roll number, the transformation function $z = x + a_r \sin(b_r x)$ was applied to the NO2 feature ($x$).

| Parameter | Value | Formula |
| :--- | :--- | :--- |
| **Roll Number (r)** | 102317172 | $r$ |
| **$a_r$** | 3.0 | $0.5 \times (r \pmod 7)$ |
| **$b_r$** | 0.9 | $0.3 \times (r \pmod 5 + 1)$ |

---

## 2. GAN Architecture Description
The model utilizes an adversarial framework to map Gaussian noise to the target distribution without assuming a parametric form.

### Generator Network
* **Input**: 1D Latent Vector $\epsilon \sim \mathcal{N}(0,1)$
* **Structure**: 4-layer Fully Connected Network
    * `Linear(1, 64)` -> `LeakyReLU(0.2)`
    * `Linear(64, 128)` -> `LeakyReLU(0.2)`
    * `Linear(128, 64)` -> `LeakyReLU(0.2)`
    * `Linear(64, 1)` (Output $z_f$)

### Discriminator Network
* **Input**: 1D Sample (Real $z$ or Fake $z_f$)
* **Structure**: 3-layer Fully Connected Network
    * `Linear(1, 64)` -> `LeakyReLU(0.2)`
    * `Linear(64, 128)` -> `LeakyReLU(0.2)`
    * `Linear(128, 1)` -> `Sigmoid` (Binary Classification)

---

## 3. Results (PDF Approximation)
The probability density was estimated using Kernel Density Estimation (KDE) on 10,000 samples generated by the trained Generator.



> **Note:** The plot visualizes the overlap between the real transformed distribution (Blue) and the GAN-learned distribution (Red/Dashed).

---

## 4. Observations

### Mode Coverage
The GAN successfully identified the primary density modes of the transformed NO2 data. Even with the non-linear shifts introduced by the $\sin$ function, the generator successfully localized high-probability regions without suffering from significant "Mode Collapse."

### Training Stability
* **Normalization**: Applying `StandardScaler` to $z$ before training was essential for stability.
* **Optimizers**: The use of Adam with $\beta_1 = 0.5$ and a learning rate of $0.0002$ prevented the discriminator from overpowering the generator early in the training process.
* **Activations**: `LeakyReLU` ensured that gradients flowed back to the generator even for values in the negative domain, preventing "dying neurons."

### Quality of Generated Distribution
The generated distribution $p_h(z)$ shows high fidelity to the original data. The GAN effectively acts as a non-parametric density estimator, capturing the skewness and kurtosis of the air quality data without the need for a predefined mathematical PDF (like Gaussian or Exponential).

---

## How to Run
1. Ensure `india-air-quality-data.csv` is in the root directory.
2. Install dependencies: `pip install torch pandas numpy matplotlib scikit-learn scipy`
3. Execute the Python script to train the model and generate the PDF plot.
